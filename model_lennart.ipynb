{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM-NN for predicting bilateral migration flows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrict to OECD destinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167400, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oecd = [\n",
    "    \"AUS\", \"AUT\", \"BEL\", \"CAN\", \"CHL\", \"CZE\", \"DNK\", \n",
    "    \"EST\", \"FIN\", \"FRA\", \"DEU\", \"GRC\", \"HUN\", \"ISL\", \n",
    "    \"IRL\", \"ISR\", \"ITA\", \"JPN\", \"KOR\", \"LUX\", \"MEX\", \n",
    "    \"NLD\", \"NZL\", \"NOR\", \"POL\", \"PRT\", \"SVK\", \"SVN\", \n",
    "    \"ESP\", \"SWE\", \"CHE\", \"TUR\", \"GBR\", \"USA\"\n",
    "]\n",
    "\n",
    "data = data[data[\"destination_iso3\"].isin(oecd)].reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dyad indicator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dyad</th>\n",
       "      <th>origin_iso3</th>\n",
       "      <th>destination_iso3</th>\n",
       "      <th>year</th>\n",
       "      <th>total</th>\n",
       "      <th>total_linear</th>\n",
       "      <th>total_loess</th>\n",
       "      <th>gdp_growth_origin</th>\n",
       "      <th>gdp_growth_destination</th>\n",
       "      <th>gdp_origin</th>\n",
       "      <th>...</th>\n",
       "      <th>conflict_deaths_destination</th>\n",
       "      <th>pop_growth_origin</th>\n",
       "      <th>pop_growth_destination</th>\n",
       "      <th>unemployment_youth_origin</th>\n",
       "      <th>unemployment_youth_destination</th>\n",
       "      <th>origin_former_colony</th>\n",
       "      <th>common_official_language</th>\n",
       "      <th>common_spoken_language</th>\n",
       "      <th>linguistic_proximity</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1990</td>\n",
       "      <td>2657.0</td>\n",
       "      <td>2657.0</td>\n",
       "      <td>2657.000000</td>\n",
       "      <td>-2.467214</td>\n",
       "      <td>4.840929</td>\n",
       "      <td>1.413530e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.456403</td>\n",
       "      <td>0.331783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18372.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2715.6</td>\n",
       "      <td>2729.933857</td>\n",
       "      <td>9.133111</td>\n",
       "      <td>3.523357</td>\n",
       "      <td>1.897200e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.424063</td>\n",
       "      <td>0.392820</td>\n",
       "      <td>11.630</td>\n",
       "      <td>4.474</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18372.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2774.2</td>\n",
       "      <td>2796.510564</td>\n",
       "      <td>7.937292</td>\n",
       "      <td>0.900586</td>\n",
       "      <td>2.287790e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.387435</td>\n",
       "      <td>0.371192</td>\n",
       "      <td>13.787</td>\n",
       "      <td>4.363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18372.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2832.8</td>\n",
       "      <td>2855.902704</td>\n",
       "      <td>8.206979</td>\n",
       "      <td>-0.459220</td>\n",
       "      <td>2.367420e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.357966</td>\n",
       "      <td>0.324168</td>\n",
       "      <td>22.151</td>\n",
       "      <td>5.114</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18372.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2891.4</td>\n",
       "      <td>2908.074731</td>\n",
       "      <td>5.836201</td>\n",
       "      <td>1.083383</td>\n",
       "      <td>2.574400e+11</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.347024</td>\n",
       "      <td>0.279192</td>\n",
       "      <td>25.735</td>\n",
       "      <td>5.459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18372.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dyad origin_iso3 destination_iso3  year   total  total_linear  \\\n",
       "0  ARG-JPN         ARG              JPN  1990  2657.0        2657.0   \n",
       "1  ARG-JPN         ARG              JPN  1991     NaN        2715.6   \n",
       "2  ARG-JPN         ARG              JPN  1992     NaN        2774.2   \n",
       "3  ARG-JPN         ARG              JPN  1993     NaN        2832.8   \n",
       "4  ARG-JPN         ARG              JPN  1994     NaN        2891.4   \n",
       "\n",
       "   total_loess  gdp_growth_origin  gdp_growth_destination    gdp_origin  ...  \\\n",
       "0  2657.000000          -2.467214                4.840929  1.413530e+11  ...   \n",
       "1  2729.933857           9.133111                3.523357  1.897200e+11  ...   \n",
       "2  2796.510564           7.937292                0.900586  2.287790e+11  ...   \n",
       "3  2855.902704           8.206979               -0.459220  2.367420e+11  ...   \n",
       "4  2908.074731           5.836201                1.083383  2.574400e+11  ...   \n",
       "\n",
       "   conflict_deaths_destination  pop_growth_origin  pop_growth_destination  \\\n",
       "0                          NaN           1.456403                0.331783   \n",
       "1                          NaN           1.424063                0.392820   \n",
       "2                          NaN           1.387435                0.371192   \n",
       "3                          NaN           1.357966                0.324168   \n",
       "4                          NaN           1.347024                0.279192   \n",
       "\n",
       "   unemployment_youth_origin  unemployment_youth_destination  \\\n",
       "0                        NaN                             NaN   \n",
       "1                     11.630                           4.474   \n",
       "2                     13.787                           4.363   \n",
       "3                     22.151                           5.114   \n",
       "4                     25.735                           5.459   \n",
       "\n",
       "   origin_former_colony  common_official_language  common_spoken_language  \\\n",
       "0                     0                       0.0                     0.0   \n",
       "1                     0                       0.0                     0.0   \n",
       "2                     0                       0.0                     0.0   \n",
       "3                     0                       0.0                     0.0   \n",
       "4                     0                       0.0                     0.0   \n",
       "\n",
       "   linguistic_proximity  distance  \n",
       "0                   0.0  18372.04  \n",
       "1                   0.0  18372.04  \n",
       "2                   0.0  18372.04  \n",
       "3                   0.0  18372.04  \n",
       "4                   0.0  18372.04  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"dyad\"] = [f\"{origin}-{dest}\" for origin, dest in zip(data[\"origin_iso3\"], data[\"destination_iso3\"])]\n",
    "data = data[[\"dyad\"] + [col for col in data.columns if col != \"dyad\"]] # move to front\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#of_interest = [col for col in data.columns if col not in [\"origin_iso3\", \"destination_iso3\", \"year\", \"total\"]]\n",
    "\n",
    "#num_cols = len(of_interest)\n",
    "#num_rows = (num_cols + 2) // 3\n",
    "\n",
    "#fig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 5))\n",
    "#axes = axes.flatten()\n",
    "\n",
    "#for i, col in enumerate(of_interest):\n",
    "#    sns.histplot(data[col], ax=axes[i])\n",
    "#    axes[i].set_title(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing-pipeline:\n",
    "\n",
    "* Log-transform GDP, population, disaster deaths & conflict deaths\n",
    "* Normalize target & all features\n",
    "* KNN-impute for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame) -> None:\n",
    "        self.data = data\n",
    "        self.transformer = FunctionTransformer(self.__log_trans)\n",
    "        self.scaler = MinMaxScaler()\n",
    "        #self.imputer = KNNImputer()\n",
    "\n",
    "        self.logged_data = None\n",
    "        self.scaled_data = None\n",
    "\n",
    "    def __log_trans(self, x: np.array) -> np.array:\n",
    "        return np.log(x + 1)\n",
    "\n",
    "    def log_transform(self) -> None:\n",
    "        log_cols = self.data.filter(regex=\"conflict_deaths|gdp(?!_g)|disaster_deaths|population\").columns\n",
    "        logged = self.transformer.fit_transform(data[log_cols])\n",
    "        self.data[log_cols] = logged\n",
    "    \n",
    "    def normalize(self) -> None:\n",
    "        to_scale = self.data.select_dtypes(include=\"number\").drop(\"year\", axis=1).columns\n",
    "        scaled = pd.DataFrame(self.scaler.fit_transform(self.data[to_scale]), columns=to_scale)\n",
    "        self.data[to_scale] = scaled\n",
    "\n",
    "    def run_pipeline(self) -> pd.DataFrame:\n",
    "        self.log_transform()\n",
    "        self.normalize()\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dyad</th>\n",
       "      <th>origin_iso3</th>\n",
       "      <th>destination_iso3</th>\n",
       "      <th>year</th>\n",
       "      <th>total</th>\n",
       "      <th>total_linear</th>\n",
       "      <th>total_loess</th>\n",
       "      <th>gdp_growth_origin</th>\n",
       "      <th>gdp_growth_destination</th>\n",
       "      <th>gdp_origin</th>\n",
       "      <th>...</th>\n",
       "      <th>conflict_deaths_destination</th>\n",
       "      <th>pop_growth_origin</th>\n",
       "      <th>pop_growth_destination</th>\n",
       "      <th>unemployment_youth_origin</th>\n",
       "      <th>unemployment_youth_destination</th>\n",
       "      <th>origin_former_colony</th>\n",
       "      <th>common_official_language</th>\n",
       "      <th>common_spoken_language</th>\n",
       "      <th>linguistic_proximity</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1990</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.287730</td>\n",
       "      <td>0.569837</td>\n",
       "      <td>0.656461</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619732</td>\n",
       "      <td>0.338260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.015510</td>\n",
       "      <td>0.341932</td>\n",
       "      <td>0.540971</td>\n",
       "      <td>0.676579</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619045</td>\n",
       "      <td>0.345364</td>\n",
       "      <td>0.139952</td>\n",
       "      <td>0.033210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.015516</td>\n",
       "      <td>0.336344</td>\n",
       "      <td>0.483509</td>\n",
       "      <td>0.689376</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.618267</td>\n",
       "      <td>0.342847</td>\n",
       "      <td>0.166584</td>\n",
       "      <td>0.031224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.337604</td>\n",
       "      <td>0.453717</td>\n",
       "      <td>0.691715</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617641</td>\n",
       "      <td>0.337374</td>\n",
       "      <td>0.269854</td>\n",
       "      <td>0.044662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG-JPN</td>\n",
       "      <td>ARG</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>0.326527</td>\n",
       "      <td>0.487514</td>\n",
       "      <td>0.697444</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.617409</td>\n",
       "      <td>0.332139</td>\n",
       "      <td>0.314105</td>\n",
       "      <td>0.050836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dyad origin_iso3 destination_iso3  year     total  total_linear  \\\n",
       "0  ARG-JPN         ARG              JPN  1990  0.000218      0.000218   \n",
       "1  ARG-JPN         ARG              JPN  1991       NaN      0.000223   \n",
       "2  ARG-JPN         ARG              JPN  1992       NaN      0.000228   \n",
       "3  ARG-JPN         ARG              JPN  1993       NaN      0.000233   \n",
       "4  ARG-JPN         ARG              JPN  1994       NaN      0.000238   \n",
       "\n",
       "   total_loess  gdp_growth_origin  gdp_growth_destination  gdp_origin  ...  \\\n",
       "0     0.015504           0.287730                0.569837    0.656461  ...   \n",
       "1     0.015510           0.341932                0.540971    0.676579  ...   \n",
       "2     0.015516           0.336344                0.483509    0.689376  ...   \n",
       "3     0.015520           0.337604                0.453717    0.691715  ...   \n",
       "4     0.015525           0.326527                0.487514    0.697444  ...   \n",
       "\n",
       "   conflict_deaths_destination  pop_growth_origin  pop_growth_destination  \\\n",
       "0                          NaN           0.619732                0.338260   \n",
       "1                          NaN           0.619045                0.345364   \n",
       "2                          NaN           0.618267                0.342847   \n",
       "3                          NaN           0.617641                0.337374   \n",
       "4                          NaN           0.617409                0.332139   \n",
       "\n",
       "   unemployment_youth_origin  unemployment_youth_destination  \\\n",
       "0                        NaN                             NaN   \n",
       "1                   0.139952                        0.033210   \n",
       "2                   0.166584                        0.031224   \n",
       "3                   0.269854                        0.044662   \n",
       "4                   0.314105                        0.050836   \n",
       "\n",
       "   origin_former_colony  common_official_language  common_spoken_language  \\\n",
       "0                   0.0                       0.0                     0.0   \n",
       "1                   0.0                       0.0                     0.0   \n",
       "2                   0.0                       0.0                     0.0   \n",
       "3                   0.0                       0.0                     0.0   \n",
       "4                   0.0                       0.0                     0.0   \n",
       "\n",
       "   linguistic_proximity  distance  \n",
       "0                   0.0  0.937821  \n",
       "1                   0.0  0.937821  \n",
       "2                   0.0  0.937821  \n",
       "3                   0.0  0.937821  \n",
       "4                   0.0  0.937821  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = DataPipeline(data=data)\n",
    "test = pipeline.run_pipeline()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes for Imputation strategy:*\n",
    "\n",
    "* KNN-imputation maybe too costly (does not run on my machine)\n",
    "* Model-based imputation:\n",
    "    - `scikit-learn` has `IterativeImputer` which fits models (feature with mis. as outcome, all other as predictors) to impute, *but:* currently in experimental stage, would not rely on for project\n",
    "    - R has tree/random forest-based imputation (e.g. missForest) which could be a solution (all numeric features & target plus one-hot encoded dyads as predictors?); no implementation in python apparently \n",
    "        * Would also be nice given it should be able to account for more complex, non-linear relationships\n",
    "\n",
    "*See:*\n",
    "\n",
    "[Paper on RF-Imputation](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-01080-1) (Some strange sounding findings though)\n",
    "\n",
    "[RF imputation for medical data](https://watermark.silverchair.com/kwt312.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAA0owggNGBgkqhkiG9w0BBwagggM3MIIDMwIBADCCAywGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMyeAqdKwxtiAv4QpHAgEQgIIC_b8zUvt0xk0fuxdJpzaxdjFsUHHknechnsRP4fa9ptKCF5LptJrDGm4WCSSzgB9_kpUT32K6QMshaiqH4kjhZiA3NgBxK3F4Rdv5X0dj2QzPIJrnX8vZuNy3gHnha1Nhn3Z3pubYNa-0E9MVZYe2M3_kb2dvKSSk9nOhHMrKWDeMQVxJ5p1wEznbvZedWtTizsqTFEpaW6gQI02kaY78e4zsir-yyE45t4hJPAkIf_j5v5OZ8YIDBHgPjbhC30gFK6GEvUoioUZXgBVHXB1IF7tDdKaZYFxqE4OeJNeumy3nWu9DVWpoYTbKfqXns6ULDEl92mLURRs6AD7BY3UrWXgsQ_ePRtoUTRGQU_oki4LJovlwBpn0vFr2bg3jayHiTwKwk27BDqIK-9FCxMlPh2W9-66v1mAk5ceNCkx6quesGMId4xT7sMZku2fH33xx0Xwc0mShkdyrm6-QCKReh5q6BrGbeaf5_1mFJ7IS-hOPIDsw4EWYLldTMYHjqK1nfqeDlHJJ8zl510iajnr4Rx5bzNFHuHiKAWpuEmz4esMGA-QJokGwqxiLks_VOaQ7Pr_5we22TEXawq-4vld5H8hl8evIcS39vgVvwB0_5lM7GHYLBgPzSfqvZaKN5Hc2buqasx49BZUyLhi65m33AsQPCMKSNEWqIv5nVtij4U5-ZBr_JYlWkUHNa0yG4xrob7_YyaXJ2TczSkxKByeACPRJf3x7pQVC0ciorLXGEFzRUuIy_gznMpwYCu6DA6MtlhBhZ6nQ1HEGLWCXFfRnBx0S5hipGNGsRpNEEpAJhi5Uefeiy4qa5arGcd6N9xR4S8TsgGAUoPFqXiVgK2RUsTbmDHSAc6348Xp0KNQIWvwLr1-DpstGo1fv_bBxz4w8K-enWx6KK49m7wqaG1WwU60OAzTeCXh77Cqhacjd9t5Gz6nIvmCZbbifldxGMtP20-5PHqRLEdDtASpAY5u1RGuXCAgkXPyg5NMo7XfVi4ns2t5ONnlVtpc8c9aHJg)\n",
    "\n",
    "[Review of RF imputation](https://arxiv.org/pdf/1701.05305):\n",
    "\n",
    "* Performance generally robust, increasing with higher feature correlation\n",
    "* Can deal with high missingness\n",
    "* Handles non-random missingness well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.get_dummies(test, columns=[\"dyad\"], prefix=\"dyad_\") # crashes when using `dtype`-argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'ARG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      2\u001b[0m imputer \u001b[38;5;241m=\u001b[39m IterativeImputer(estimator\u001b[38;5;241m=\u001b[39mrf, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(imputer\u001b[38;5;241m.\u001b[39mfit_transform(test))\n\u001b[1;32m      5\u001b[0m test\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/impute/_iterative.py:715\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_sequence_ \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_imputer_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m X, Xt, mask_missing_values, complete_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial_imputation(\n\u001b[1;32m    716\u001b[0m     X, in_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    717\u001b[0m )\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit_indicator(complete_mask)\n\u001b[1;32m    720\u001b[0m X_indicator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_transform_indicator(complete_mask)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/impute/_iterative.py:608\u001b[0m, in \u001b[0;36mIterativeImputer._initial_imputation\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    606\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    609\u001b[0m     X,\n\u001b[1;32m    610\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[1;32m    611\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    612\u001b[0m     reset\u001b[38;5;241m=\u001b[39min_fit,\n\u001b[1;32m    613\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m    614\u001b[0m )\n\u001b[1;32m    615\u001b[0m _check_inputs_dtype(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values)\n\u001b[1;32m    617\u001b[0m X_missing_mask \u001b[38;5;241m=\u001b[39m _get_mask(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:838\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    837\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 838\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(new_dtype)\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    840\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   6320\u001b[0m     ]\n\u001b[1;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    454\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    455\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    456\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[1;32m    457\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    184\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:138\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'ARG'"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "imputer = IterativeImputer(estimator=rf, random_state=42)\n",
    "\n",
    "to_impute = test.select_dtypes(include=[\"number\", \"boolean\"]).drop([\"year\", \"total\"], axis=1).columns\n",
    "test = pd.DataFrame(imputer.fit_transform(test[to_impute]))\n",
    "test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
